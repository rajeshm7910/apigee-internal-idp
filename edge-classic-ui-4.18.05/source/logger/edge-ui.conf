<source>
type tail
#Following line is added to push the log from the beginning. This is not a problem in case of AMI as pos and log files
# are generated at the same time. Please be careful if you are copy paste this config somewhere else.
read_from_head true
path {T}conf_logger_component_logger_logdir{/T}/application*.log
 pos_file {T}conf_logger_component_logger_logdir{/T}/classic-edge-ui.pos
 tag classic-edge-ui_logs
 format multiline
 format_firstline /^\d{4}-\d{1,2}-\d{1,2}/
 format1 /^(?<time>\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2},\d{1,3}) \[(?<level>[^\]]*)\] (?<message>.*)/
</source>

<filter classic-edge-ui_logs>
  type record_transformer
  <record>
    host {T}conf_logger_host{/T}
    region {T}conf_logger_region{/T}
    pod {T}conf_logger_pod{/T}
    az {T}conf_logger_az{/T}
    release {T}conf_logger_release{/T}
    dpcolor {T}conf_logger_dpcolor{/T}
  </record>
</filter>

<match classic-edge-ui_logs>
    @type copy
    <store>
      @type google_cloud
        # Set the chunk limit conservatively to avoid exceeding the limit
        # of 10MB per write request.
          buffer_chunk_limit {T}conf_logger_gc_buffer_chunk_limit{/T}
          flush_interval {T}conf_logger_gc_flush_interval{/T}
          # Never wait longer than 5 minutes between retries.
          max_retry_wait {T}conf_logger_gc_max_retry_wait{/T}
         # Disable the limit on the number of retries (retry forever).
         disable_retry_limit
         # Use multiple threads for processing.
          num_threads {T}conf_logger_gc_num_threads{/T}
   </store>
</match>
